'use client'

import { Dropzone, DropzoneContent, DropzoneEmptyState } from '@/components/dropzone'
import { createClient } from '@/lib/supabase/client'
import { useSupabaseUpload } from '@/hooks/use-supabase-upload'
import { useQueueMonitor } from '@/hooks/use-queue-monitor'
import { useEffect, useState, useCallback, useRef } from 'react'
import { useRouter } from 'next/navigation'
import { Play, Pause, Mic, Square, RotateCcw, Music } from 'lucide-react'
import { QueueStatusDisplay } from '@/components/QueueStatusDisplay'

// Supabase Storage list ë°˜í™˜ ê°ì²´ íƒ€ì… ì •ì˜
type StorageObject = {
  name: string;
  id: string;
  updated_at: string;
  created_at: string;
  last_accessed_at: string;
  metadata?: object;
};

  // ë¯¸ë¦¬ ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ íŒŒì¼ ëª©ë¡
  const PRESET_AUDIO_FILES = [
    { name: 'ìœ ì¬ì„ ì°¸ê³ ìŒì„±', file: '/yoojaeseok_ref1.wav', duration: 'ì•½ 10ì´ˆ' },
    { name: 'ì†ì„í¬ ì°¸ê³ ìŒì„±', file: '/sonsukhee_ref1.wav', duration: 'ì•½ 8ì´ˆ' },
    { name: 'ì´ë™ì§„ ì°¸ê³ ìŒì„±', file: '/leedongjin_ref0.wav', duration: 'ì•½ 8ì´ˆ' },
    { name: 'ì•„ì´ìœ  ì°¸ê³ ìŒì„±', file: '/iu_ref0.wav', duration: 'ì•½ 10ì´ˆ' },
    { name: 'í”„ë‘ìŠ¤ íŠœí„°', file: '/franch_tutor.wav', duration: 'ì•½ 9ì´ˆ' },
    { name: 'ì¹¨ì°©ë§¨', file: '/chimchakman.wav', duration: 'ì•½ 9ì´ˆ' },
    { name: 'ì§€ë“œë˜ê³¤ ì°¸ê³ ìŒì„±', file: '/gdragon_ref1.wav', duration: 'ì•½ 9ì´ˆ' },
  ]

  // í…ìŠ¤íŠ¸ ì˜ˆì‹œ ëª©ë¡
  const TEXT_EXAMPLES = [
    {
      id: 1,
      title: 'ê°ì‚¬ì™€ ì‚¬ë‘ì˜ ë©”ì‹œì§€',
      text: 'ì¢‹ì•„í•˜ëŠ” ê²ƒ, ì‹«ì–´í•˜ëŠ” ê²ƒ, ì‚¬ì†Œí•œ ìŠµê´€ê¹Œì§€ ì„¬ì„¸í•˜ê²Œ ê¸°ì–µí•´ ì£¼ëŠ” ë„ˆë¥¼ ë³´ë©´ì„œ ì´ëŸ° ì‚¬ëŒì´ ê³ì— ìˆë‹¤ëŠ” ê²Œ ì–¼ë§ˆë‚˜ í° ì¶•ë³µì¸ì§€ ì•Œê²Œ ëì–´.'
    },
    {
      id: 2,
      title: 'ìœ„ë¡œì™€ ê²©ë ¤',
      text: 'ì˜¤ëŠ˜ í•˜ë£¨ë„ ì •ë§ ê³ ìƒ ë§ì•˜ì–´ìš”. ëˆˆì— ë³´ì´ì§€ ì•ŠëŠ” ë…¸ë ¥ê¹Œì§€ë„ ëˆ„êµ°ê°€ëŠ” ë¶„ëª…íˆ ì•Œê³  ìˆì„ ê±°ì˜ˆìš”.'
    },
    {
      id: 3,
      title: 'ì§€ì§€ì™€ ì‘ì›',
      text: 'ë‹¹ì‹ ì´ ì–¼ë§ˆë‚˜ ì—´ì‹¬íˆ ì‚´ì•„ê°€ê³  ìˆëŠ”ì§€ ì˜ ì•Œì•„ìš”. ë¹„ë¡ ì§€ê¸ˆì€ ê²°ê³¼ê°€ ë³´ì´ì§€ ì•Šë”ë¼ë„, ê·¸ ëª¨ë“  ì‹œê°„ê³¼ ë§ˆìŒì€ í—›ë˜ì§€ ì•Šì„ ê±°ì˜ˆìš”.'
    },
    {
      id: 4,
      title: 'ë”°ëœ»í•œ ìœ„ë¡œ',
      text: 'ê´œíˆ ë„¤ ë§ˆìŒì†ì— ë‹µì„ í˜¼ìì„œë§Œ í’ˆê³  ê³ ë¯¼í•˜ì§€ ì•Šì•˜ìœ¼ë©´ í•´. ì–¸ì œë“  ê´œì°®ìœ¼ë‹ˆ, ë„¤ê°€ í•˜ê³  ì‹¶ì€ ë§ì´ ìˆë‹¤ë©´ ë¶€ë‹´ ê°–ì§€ ë§ê³  ì´ì•¼ê¸°í•´ì¤˜.'
    },
    {
      id: 5,
      title: 'ê°ì‚¬ì˜ ë§ˆìŒ',
      text: 'ì§€ê¸ˆê¹Œì§€ ì œê°€ ì—¬ê¸°ê¹Œì§€ ì˜¬ ìˆ˜ ìˆì—ˆë˜ ê±´ ë‹¤ ë¶€ëª¨ë‹˜ ë•ë¶„ì´ì—ìš”. ë§ë¡œ ë‹¤ í‘œí˜„í•  ìˆœ ì—†ì§€ë§Œ, ë§ˆìŒì†ìœ¼ë¡  ëŠ˜ ê°ì‚¬í•˜ê³  ë˜ ê°ì‚¬í•˜ê³  ìˆì–´ìš”.'
    }
  ]

const FileUploadDemo = () => {
  const [userId, setUserId] = useState<string | null>(null)
  const [gen_text, setGenText] = useState('')
  const [isProcessing, setIsProcessing] = useState(false)
  const [errorMessage, setErrorMessage] = useState('')
  const [showPreview, setShowPreview] = useState(false)
  const [audioUrl, setAudioUrl] = useState<string | null>(null)
  const [isPlaying, setIsPlaying] = useState(false)
  const [audioElement, setAudioElement] = useState<HTMLAudioElement | null>(null)
  const audioUrlRef = useRef<string | null>(null)
  
  // ì˜¤ë””ì˜¤ ì§„í–‰ë¥  ê´€ë ¨ ìƒíƒœ
  const [currentTime, setCurrentTime] = useState(0)
  const [duration, setDuration] = useState(0)
  
  // ë…¹ìŒ ê´€ë ¨ ìƒíƒœ
  const [isRecording, setIsRecording] = useState(false)
  const [recordingTime, setRecordingTime] = useState(0)
  const [mediaRecorder, setMediaRecorder] = useState<MediaRecorder | null>(null)
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  const [audioChunks, setAudioChunks] = useState<Blob[]>([])
  const [recordedAudioBlob, setRecordedAudioBlob] = useState<Blob | null>(null)
  const [recordingTimer, setRecordingTimer] = useState<NodeJS.Timeout | null>(null)
  
  // í˜„ì¬ ë‹¨ê³„ ê´€ë¦¬
  const [currentStep, setCurrentStep] = useState<'upload' | 'preview' | 'text'>('upload')
  
  // ë¯¸ë¦¬ ì„ íƒëœ ì˜¤ë””ì˜¤ ê´€ë ¨ ìƒíƒœ
  const [selectedPresetAudio, setSelectedPresetAudio] = useState<string | null>(null)
  const [showPresetAudioList, setShowPresetAudioList] = useState(false)
  
  // ì´ì „ì— ì‚¬ìš©í•œ ìŒì„± ê´€ë ¨ ìƒíƒœ
  const [usedAudioFile, setUsedAudioFile] = useState<string | null>(null)
  
  // í…ìŠ¤íŠ¸ ì˜ˆì‹œ ê´€ë ¨ ìƒíƒœ
  const [showTextExamples, setShowTextExamples] = useState(false)
  

  
  // ì´ì „ì— ì‚¬ìš©í•œ ìŒì„± ë¦¬ìŠ¤íŠ¸ ìƒíƒœ ë° í‘œì‹œ ì—¬ë¶€ ìƒíƒœ ì¶”ê°€
  const [usedAudioFiles, setUsedAudioFiles] = useState<Array<{ name: string; file: string }>>([])
  
  // TTS ìš”ì²­ ìƒíƒœ ê´€ë¦¬
  const [currentRequestId, setCurrentRequestId] = useState<string | null>(null)
  const [showUsedAudioList, setShowUsedAudioList] = useState(false)
  
  const supabase = createClient()
  const router = useRouter()

  // useQueueMonitor í›… ì‚¬ìš©
  const { isCompleted } = useQueueMonitor({ 
    requestId: currentRequestId, 
    enabled: !!currentRequestId 
  })

  // ì™„ë£Œ ê°ì§€ ì‹œ ë„¤ë¹„ê²Œì´ì…˜
  useEffect(() => {
    if (isCompleted && currentRequestId) {
      console.log('âœ… TTS completed, navigating to results page...')
      // ì¦‰ì‹œ ê²°ê³¼ í˜ì´ì§€ë¡œ ì´ë™
      router.push('/user/results')
    }
  }, [isCompleted, currentRequestId, router])

  // audioUrlì´ ë³€ê²½ë  ë•Œë§ˆë‹¤ ref ì—…ë°ì´íŠ¸
  useEffect(() => {
    audioUrlRef.current = audioUrl
  }, [audioUrl])

  // ë¡œê·¸ì¸í•œ ì‚¬ìš©ì ì •ë³´ ê°€ì ¸ì˜¤ê¸°
  useEffect(() => {
    const fetchUser = async () => {
      const {
        data: { user },
      } = await supabase.auth.getUser()
      if (user) {
        setUserId(user.id)
      }
    }
    fetchUser()
  }, [supabase])

  // ì˜¤ë””ì˜¤ ì¬ìƒ/ì¼ì‹œì •ì§€ í† ê¸€
  const togglePlayPause = useCallback(() => {
    if (audioElement) {
      if (isPlaying) {
        audioElement.pause()
      } else {
        audioElement.play()
      }
      setIsPlaying(!isPlaying)
    }
  }, [audioElement, isPlaying])

  // ì˜¤ë””ì˜¤ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì„¤ì •
  useEffect(() => {
    if (audioElement) {
      const handleEnded = () => setIsPlaying(false)
      const handlePlay = () => setIsPlaying(true)
      const handlePause = () => setIsPlaying(false)
      const handleTimeUpdate = () => setCurrentTime(audioElement.currentTime)
      const handleLoadedMetadata = () => {
        if (audioElement.duration && !isNaN(audioElement.duration)) {
          setDuration(audioElement.duration)
        }
      }
      const handleError = () => {
        console.error('ì˜¤ë””ì˜¤ ë¡œë”© ì‹¤íŒ¨')
        setDuration(0)
        setCurrentTime(0)
      }

      audioElement.addEventListener('ended', handleEnded)
      audioElement.addEventListener('play', handlePlay)
      audioElement.addEventListener('pause', handlePause)
      audioElement.addEventListener('timeupdate', handleTimeUpdate)
      audioElement.addEventListener('loadedmetadata', handleLoadedMetadata)
      audioElement.addEventListener('error', handleError)

      return () => {
        audioElement.removeEventListener('ended', handleEnded)
        audioElement.removeEventListener('play', handlePlay)
        audioElement.removeEventListener('pause', handlePause)
        audioElement.removeEventListener('timeupdate', handleTimeUpdate)
        audioElement.removeEventListener('loadedmetadata', handleLoadedMetadata)
        audioElement.removeEventListener('error', handleError)
      }
    }
  }, [audioElement])

  // íŒŒì¼ì´ ì„ íƒë˜ë©´ ë¯¸ë¦¬ë³´ê¸° URL ìƒì„±
  const handleFileSelect = useCallback((files: File[]) => {
    if (files.length > 0) {
      const file = files[0]
      const url = URL.createObjectURL(file)
      setAudioUrl(url)
      setShowPreview(true)
      setCurrentStep('preview')
      
      // ìƒˆë¡œìš´ ì˜¤ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ ìƒì„±
      const audio = new Audio(url)
      setAudioElement(audio)
      setIsPlaying(false)
      setCurrentTime(0)
      setDuration(0)
    }
  }, [])

  // íŒŒì¼ ì •ë¦¬ í•¨ìˆ˜
  const clearAudioPreview = useCallback(() => {
    setShowPreview(false)
    if (audioUrlRef.current) {
      URL.revokeObjectURL(audioUrlRef.current)
      setAudioUrl(null)
    }
    setAudioElement(null)
    setIsPlaying(false)
    setCurrentStep('upload')
  }, [])

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ URL ì •ë¦¬
  useEffect(() => {
    return () => {
      if (audioUrlRef.current) {
        URL.revokeObjectURL(audioUrlRef.current)
      }
      // ë…¹ìŒ íƒ€ì´ë¨¸ ì •ë¦¬
      if (recordingTimer) {
        clearInterval(recordingTimer)
      }
    }
  }, [recordingTimer])

  // ë…¹ìŒ ì‹œì‘ í•¨ìˆ˜
  const startRecording = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      const recorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      })
      
      const chunks: Blob[] = []
      
      recorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunks.push(event.data)
        }
      }
      
      recorder.onstop = () => {
        const blob = new Blob(chunks, { type: 'audio/webm' })
        setRecordedAudioBlob(blob)
        setAudioChunks(chunks)
        setCurrentStep('preview')
        
        // ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
        stream.getTracks().forEach(track => track.stop())
      }
      
      recorder.start()
      setMediaRecorder(recorder)
      setIsRecording(true)
      setRecordingTime(0)
      
      // ë…¹ìŒ ì‹œê°„ íƒ€ì´ë¨¸ ì‹œì‘
      const timer = setInterval(() => {
        setRecordingTime(prev => prev + 1)
      }, 1000)
      setRecordingTimer(timer)
      
    } catch (error) {
      console.error('ë…¹ìŒì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤:', error)
      setErrorMessage('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.')
    }
  }, [])

  // ë…¹ìŒ ì¤‘ì§€ í•¨ìˆ˜
  const stopRecording = useCallback(() => {
    if (mediaRecorder && isRecording) {
      mediaRecorder.stop()
      setIsRecording(false)
      
      // íƒ€ì´ë¨¸ ì •ë¦¬
      if (recordingTimer) {
        clearInterval(recordingTimer)
        setRecordingTimer(null)
      }
    }
  }, [mediaRecorder, isRecording, recordingTimer])

  // ë…¹ìŒ ì¬ì‹œì‘ í•¨ìˆ˜
  const restartRecording = useCallback(() => {
    setRecordedAudioBlob(null)
    setAudioChunks([])
    setRecordingTime(0)
    setShowPreview(false)
    if (audioUrlRef.current) {
      URL.revokeObjectURL(audioUrlRef.current)
      setAudioUrl(null)
    }
    setAudioElement(null)
    setIsPlaying(false)
    setCurrentStep('upload')
    setSelectedPresetAudio(null)
    setUsedAudioFile(null)
  }, [])

  // ë…¹ìŒëœ ì˜¤ë””ì˜¤ë¥¼ íŒŒì¼ë¡œ ë³€í™˜í•˜ê³  ë¯¸ë¦¬ë³´ê¸° ì„¤ì •
  const handleRecordedAudio = useCallback(() => {
    if (recordedAudioBlob) {
      const url = URL.createObjectURL(recordedAudioBlob)
      setAudioUrl(url)
      setShowPreview(true)
      
      // ìƒˆë¡œìš´ ì˜¤ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ ìƒì„±
      const audio = new Audio(url)
      setAudioElement(audio)
      setIsPlaying(false)
      setCurrentTime(0)
      setDuration(0)
    }
  }, [recordedAudioBlob])

  // ë¯¸ë¦¬ ì„ íƒëœ ì˜¤ë””ì˜¤ ì²˜ë¦¬ í•¨ìˆ˜
  const handlePresetAudioSelect = useCallback((audioFile: string) => {
    console.log('ë¯¸ë¦¬ ì„ íƒëœ ì˜¤ë””ì˜¤ ì„ íƒ:', audioFile)
    console.log('í˜„ì¬ currentStep:', currentStep)
    console.log('í˜„ì¬ showPreview:', showPreview)
    
    setSelectedPresetAudio(audioFile)
    setAudioUrl(audioFile)
    setShowPreview(true)
    setCurrentStep('preview')
    
    // ìƒˆë¡œìš´ ì˜¤ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ ìƒì„±
    const audio = new Audio(audioFile)
    setAudioElement(audio)
    setIsPlaying(false)
    setCurrentTime(0)
    setDuration(0)
    
    // ë…¹ìŒ ê´€ë ¨ ìƒíƒœ ì´ˆê¸°í™”
    setRecordedAudioBlob(null)
    setAudioChunks([])
    setRecordingTime(0)
    
    setShowPresetAudioList(false)
    console.log('ë¯¸ë¦¬ ì„ íƒëœ ì˜¤ë””ì˜¤ ì„¤ì • ì™„ë£Œ')
    console.log('ì„¤ì • í›„ currentStep:', 'preview')
    console.log('ì„¤ì • í›„ showPreview:', true)
  }, [currentStep, showPreview])

  // í…ìŠ¤íŠ¸ ì˜ˆì‹œ ì„ íƒ í•¨ìˆ˜
  const handleTextExampleSelect = useCallback((exampleText: string) => {
    setGenText(exampleText)
    setShowTextExamples(false)
  }, [])

  // ë¯¸ë¦¬ ì„ íƒëœ ì˜¤ë””ì˜¤ë¥¼ Supabaseì— ì—…ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
  const uploadPresetAudio = useCallback(async (): Promise<string | null> => {
    if (!selectedPresetAudio || !userId) return null
    
    try {
      // ë¯¸ë¦¬ ì„ íƒëœ ì˜¤ë””ì˜¤ íŒŒì¼ì„ fetchë¡œ ê°€ì ¸ì™€ì„œ Blobìœ¼ë¡œ ë³€í™˜
      const response = await fetch(selectedPresetAudio)
      if (!response.ok) {
        throw new Error('Failed to fetch preset audio')
      }
      
      const blob = await response.blob()
      
      // íŒŒì¼ëª… ì¶”ì¶œ
      const fileName = `${Date.now()}_${selectedPresetAudio.split('/').pop()}`;
      const filePath = `reference/${userId}/${fileName}`;
      
      // Supabase Storageì— ì—…ë¡œë“œ
      const { error } = await supabase.storage
        .from('prototype')
        .upload(filePath, blob, {
          cacheControl: '3600',
          upsert: true // ë°˜ë“œì‹œ trueë¡œ!
        })
      
      if (error) {
        console.error('ë¯¸ë¦¬ ì„ íƒëœ ì˜¤ë””ì˜¤ ì—…ë¡œë“œ ì‹¤íŒ¨:', error)
        setErrorMessage('ë¯¸ë¦¬ ì„ íƒëœ ì˜¤ë””ì˜¤ ì—…ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.')
        return null
      }
      
      return filePath
    } catch (error) {
      console.error('ë¯¸ë¦¬ ì„ íƒëœ ì˜¤ë””ì˜¤ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜:', error)
      setErrorMessage('ë¯¸ë¦¬ ì„ íƒëœ ì˜¤ë””ì˜¤ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')
      return null
    }
  }, [selectedPresetAudio, userId, supabase])

  // ì´ì „ì— ì‚¬ìš©í•œ ìŒì„± ì²˜ë¦¬ í•¨ìˆ˜ (ì´ë¯¸ ì—…ë¡œë“œëœ íŒŒì¼ì´ë¯€ë¡œ ë³µì‚¬ë§Œ ìˆ˜í–‰)
  const handleUsedAudioFile = useCallback(async (): Promise<string | null> => {
    if (!usedAudioFile || !userId) return null
    
    try {
      // ê¸°ì¡´ íŒŒì¼ ê²½ë¡œì—ì„œ ìƒˆ íŒŒì¼ëª… ìƒì„±
      const originalFileName = usedAudioFile.split('/').pop();
      const newFileName = `${Date.now()}_${originalFileName}`;
      const newFilePath = `reference/${userId}/${newFileName}`;
      
      // ê¸°ì¡´ íŒŒì¼ì„ ìƒˆ ê²½ë¡œë¡œ ë³µì‚¬
      const { error } = await supabase.storage
        .from('prototype')
        .copy(usedAudioFile, newFilePath)
      
      if (error) {
        console.error('ì´ì „ ì‚¬ìš© ìŒì„± ë³µì‚¬ ì‹¤íŒ¨:', error)
        setErrorMessage('ì´ì „ ì‚¬ìš© ìŒì„± ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.')
        return null
      }
      
      return newFilePath
    } catch (error) {
      console.error('ì´ì „ ì‚¬ìš© ìŒì„± ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:', error)
      setErrorMessage('ì´ì „ ì‚¬ìš© ìŒì„± ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')
      return null
    }
  }, [usedAudioFile, userId, supabase])

  // ë…¹ìŒëœ ì˜¤ë””ì˜¤ê°€ ë³€ê²½ë  ë•Œë§ˆë‹¤ ë¯¸ë¦¬ë³´ê¸° ì„¤ì •
  useEffect(() => {
    if (recordedAudioBlob) {
      handleRecordedAudio()
    }
  }, [recordedAudioBlob, handleRecordedAudio])

  // ë…¹ìŒëœ ì˜¤ë””ì˜¤ë¥¼ Supabaseì— ì—…ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
  const uploadRecordedAudio = useCallback(async (): Promise<string | null> => {
    if (!recordedAudioBlob || !userId) return null
    
    try {
      // Blobì„ File ê°ì²´ë¡œ ë³€í™˜
      const file = new File([recordedAudioBlob], `recorded_audio_${Date.now()}.webm`, {
        type: 'audio/webm'
      })
      
      // Supabase Storageì— ì—…ë¡œë“œ
      const fileName = `reference/${userId}/recorded_${Date.now()}.webm`
      const { error } = await supabase.storage
        .from('prototype')
        .upload(fileName, file, {
          cacheControl: '3600',
          upsert: false
        })
      
      if (error) {
        console.error('ë…¹ìŒ ì˜¤ë””ì˜¤ ì—…ë¡œë“œ ì‹¤íŒ¨:', error)
        setErrorMessage('ë…¹ìŒ ì˜¤ë””ì˜¤ ì—…ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.')
        return null
      }
      
      return fileName
    } catch (error) {
      console.error('ë…¹ìŒ ì˜¤ë””ì˜¤ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜:', error)
      setErrorMessage('ë…¹ìŒ ì˜¤ë””ì˜¤ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')
      return null
    }
  }, [recordedAudioBlob, userId, supabase])

  // ì¤‘ë³µ ìš”ì²­ í™•ì¸ í•¨ìˆ˜ - ëª¨ë“  ì§„í–‰ ì¤‘ì¸ ìƒíƒœ í™•ì¸
  const checkDuplicateRequest = async (userId: string, input_text: string, reference_id: string) => {
    const { data, error } = await supabase
      .from('tts_requests')
      .select('request_id, status')
      .eq('user_id', userId)
      .eq('input_text', input_text)
      .eq('reference_id', reference_id)
      .in('status', ['pending', 'processing'])
      .limit(5) // ìµœê·¼ ìš”ì²­ ëª‡ ê°œ í™•ì¸
    
    if (error) {
      console.error('ì¤‘ë³µ í™•ì¸ ì¤‘ ì˜¤ë¥˜:', error)
      return false
    }
    
    // ì§„í–‰ ì¤‘ì¸ ìš”ì²­ì´ ìˆìœ¼ë©´ ì¤‘ë³µìœ¼ë¡œ íŒë‹¨
    if (data && data.length > 0) {
      console.log('ì¤‘ë³µ ìš”ì²­ ê°ì§€:', {
        userId,
        input_text,
        reference_id,
        existingRequests: data
      })
      return true
    }
    
    return false
  }

  // ref_audiosì— ì˜¤ë””ì˜¤ ì—…ë¡œë“œ í›„ ref_id ë°›ì•„ì˜¤ê¸°
  const uploadReferenceAudioAndGetRefId = async (filePath: string, signedUrl: string) => {
    if (!userId) return null;
    
    // ref_audiosì— insert
    const { data, error } = await supabase
      .from('ref_audios')
      .insert({
        user_id: userId,
        ref_file_url: signedUrl,
        ref_file_path: filePath,
        is_public: false,
      })
      .select('ref_id')
      .single();
    
    if (error) {
      console.error('ì°¸ì¡° ì˜¤ë””ì˜¤ ë“±ë¡ ì‹¤íŒ¨:', error)
      setErrorMessage('ì°¸ì¡° ì˜¤ë””ì˜¤ ë“±ë¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      return null;
    }
    
    return data.ref_id;
  }

  // í…ìŠ¤íŠ¸ì™€ ì˜¤ë””ì˜¤ ì¡°í•©ìœ¼ë¡œ ì¤‘ë³µ ìš”ì²­ ì‚¬ì „ í™•ì¸
  const checkDuplicateByTextAndAudio = async (userId: string, input_text: string) => {
    // í…ìŠ¤íŠ¸ì™€ ì˜¤ë””ì˜¤ ì†ŒìŠ¤ ì¡°í•©ìœ¼ë¡œ ë¨¼ì € í™•ì¸
    const { data, error } = await supabase
      .from('tts_requests')
      .select('request_id, status, created_at')
      .eq('user_id', userId)
      .eq('input_text', input_text)
      .in('status', ['pending', 'processing'])
      .gte('created_at', new Date(Date.now() - 60000).toISOString()) // ìµœê·¼ 1ë¶„ ì´ë‚´
      .limit(3)
    
    if (error) {
      console.error('ì‚¬ì „ ì¤‘ë³µ í™•ì¸ ì¤‘ ì˜¤ë¥˜:', error)
      return false
    }
    
    return data && data.length > 0
  }

  // í†µí•©ëœ TTS ì‹œì‘ í•¨ìˆ˜ - ëª¨ë“  ì˜¤ë””ì˜¤ ì†ŒìŠ¤ ì²˜ë¦¬
  const startTTS = useCallback(async () => {
    if (!userId || !gen_text.trim()) {
      setErrorMessage('ê³„ì • ì •ë³´ ë˜ëŠ” í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.')
      return
    }
    
    // ì´ë¯¸ ì²˜ë¦¬ ì¤‘ì´ë©´ ì¤‘ë‹¨
    if (isProcessing) {
      console.log('ì´ë¯¸ ì²˜ë¦¬ ì¤‘ì¸ ìš”ì²­ì´ ìˆìŠµë‹ˆë‹¤.')
      return
    }
    
    setIsProcessing(true)
    setErrorMessage('')

    try {
      // 0ë‹¨ê³„: í…ìŠ¤íŠ¸ ê¸°ì¤€ ì‚¬ì „ ì¤‘ë³µ í™•ì¸
      const isEarlyDuplicate = await checkDuplicateByTextAndAudio(userId, gen_text)
      if (isEarlyDuplicate) {
        setErrorMessage('ë™ì¼í•œ í…ìŠ¤íŠ¸ë¡œ ìµœê·¼ì— ìš”ì²­ì´ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.')
        setIsProcessing(false)
        return
      }

      let filePath: string | null = null
      let signedUrl: string | null = null

      // 1ë‹¨ê³„: ì˜¤ë””ì˜¤ ì†ŒìŠ¤ì— ë”°ë¼ ì²˜ë¦¬
      if (recordedAudioBlob) {
        // ë…¹ìŒëœ ì˜¤ë””ì˜¤ ì²˜ë¦¬
        filePath = await uploadRecordedAudio()
      } else if (selectedPresetAudio) {
        // ë¯¸ë¦¬ ì¤€ë¹„ëœ ì˜¤ë””ì˜¤ ì²˜ë¦¬
        filePath = await uploadPresetAudio()
      } else if (usedAudioFile) {
        // ì´ì „ì— ì‚¬ìš©í•œ ì˜¤ë””ì˜¤ ì²˜ë¦¬
        filePath = await handleUsedAudioFile()
      } else {
        // íŒŒì¼ ì—…ë¡œë“œê°€ í•„ìš”í•œ ê²½ìš° - ì´ëŠ” onUploadSuccessì— ì˜í•´ ì²˜ë¦¬ë¨
        setErrorMessage('ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.')
        setIsProcessing(false)
        return
      }

      if (!filePath) {
        setIsProcessing(false)
        return
      }

      // 2ë‹¨ê³„: signed URL ìƒì„±
      const { data, error: urlError } = await supabase
        .storage
        .from('prototype')
        .createSignedUrl(filePath, 60 * 60 * 24 * 30) // 30ì¼

      if (urlError || !data?.signedUrl) {
        console.error('Error creating signed URL:', urlError?.message)
        setErrorMessage('Signed URL ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.')
        setIsProcessing(false)
        return
      }

      signedUrl = data.signedUrl

      // 3ë‹¨ê³„: ref_audiosì— insert í›„ ref_id ë°›ì•„ì˜¤ê¸°
      const ref_id = await uploadReferenceAudioAndGetRefId(filePath, signedUrl)
      if (!ref_id) {
        setIsProcessing(false)
        return
      }

      // 4ë‹¨ê³„: ì •í™•í•œ ì¤‘ë³µ ìš”ì²­ í™•ì¸
      const isDuplicate = await checkDuplicateRequest(userId, gen_text, ref_id)
      if (isDuplicate) {
        setErrorMessage('ë™ì¼í•œ ìš”ì²­ì´ ì´ë¯¸ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤.')
        setIsProcessing(false)
        return
      }

      // 4.5ë‹¨ê³„: ì¤‘ë³µ í™•ì¸ í›„ ì•½ê°„ì˜ ì§€ì—° (Race condition ë°©ì§€)
      await new Promise(resolve => setTimeout(resolve, 100))

      // 5ë‹¨ê³„: TTS Runner Edge Function í˜¸ì¶œ
      try {
        console.log('Calling TTS Runner Edge Function...')
        console.log('Request payload:', {
          reference_id: ref_id,
          reference_audio_url: signedUrl,
          input_text: gen_text,
          user_id: userId
        })
        
        const { data: functionData, error: functionError } = await supabase.functions.invoke('rapid-worker', {
          body: {
            reference_id: ref_id,
            reference_audio_url: signedUrl,
            input_text: gen_text,
            user_id: userId
          }
        })

        if (functionError) {
          console.error('Error calling TTS Runner:', functionError)
          console.error('Error details:', {
            message: functionError.message,
            name: functionError.name,
            status: functionError.status,
            statusText: functionError.statusText
          })
          
          setErrorMessage(`Edge Function í˜¸ì¶œ ì‹¤íŒ¨: ${functionError.message}`)
          setIsProcessing(false)
          return
        } else {
          console.log('TTS Runner called successfully:', functionData)
          
          // Edge Functionì—ì„œ ë°˜í™˜ëœ request_id ì‚¬ìš©
          const requestId = functionData?.request_id
          if (!requestId) {
            console.error('No request_id returned from Edge Function')
            setErrorMessage('ìš”ì²­ ID ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.')
            setIsProcessing(false)
            return
          }
          
          // í ì •ë³´ ì €ì¥
          console.log('Function data received:', functionData)
          if (functionData?.queue_info) {
            console.log('Queue info received:', functionData.queue_info)
            setCurrentRequestId(requestId)
            // ì¦‰ì‹œ í ì •ë³´ë¥¼ useQueueMonitorì— ì „ë‹¬
            console.log('âœ… Queue info immediately available')
          } else {
            console.log('No queue info in response, setting requestId anyway')
            setCurrentRequestId(requestId)
          }
          
          console.log('Request ID from Edge Function:', requestId)
          
          // useQueueMonitorê°€ í ìƒíƒœë¥¼ ê´€ë¦¬í•˜ë¯€ë¡œ ë³„ë„ í´ë§ ì œê±°
          console.log('ğŸ”„ Queue monitoring handled by useQueueMonitor hook')
        }
      } catch (functionError) {
        console.error('Error calling TTS Runner function:', functionError)
        console.error('Exception details:', {
          message: functionError instanceof Error ? functionError.message : 'Unknown error',
          stack: functionError instanceof Error ? functionError.stack : undefined
        })
        
        setErrorMessage(`Edge Function í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: ${functionError instanceof Error ? functionError.message : 'Unknown error'}`)
        setIsProcessing(false)
        return
      }
      
    } catch (error) {
      console.error('TTS ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:', error)
      setErrorMessage('TTS ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')
      setIsProcessing(false)
    }
  }, [
    userId, 
    gen_text, 
    recordedAudioBlob, 
    selectedPresetAudio, 
    usedAudioFile,
    isProcessing,
    uploadRecordedAudio,
    uploadPresetAudio,
    handleUsedAudioFile,
    supabase, 
    router
  ])

  // íŒŒì¼ ì—…ë¡œë“œ ì„±ê³µ ì‹œ í˜¸ì¶œë˜ëŠ” í•¨ìˆ˜ (ê¸°ì¡´ êµ¬ì¡° ìœ ì§€)
  const onUploadSuccess = useCallback(
    async (uploadedFileUrls: string[]) => {
      if (!userId || uploadedFileUrls.length === 0) return
      
      // íŒŒì¼ ì—…ë¡œë“œê°€ ì™„ë£Œë˜ë©´ startTTS í•¨ìˆ˜ë¥¼ í˜¸ì¶œ
      await startTTS()
    },
    [userId, startTTS]
  )







  // ì´ì „ì— ì‚¬ìš©í•œ ìŒì„± ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜
  const fetchUsedAudioFiles = useCallback(async () => {
    if (!userId) return;
    try {
      const { data, error } = await supabase.storage.from('prototype').list(`reference/${userId}/`, {
        limit: 100,
        offset: 0,
        sortBy: { column: 'name', order: 'desc' },
      });
      if (error) {
        setErrorMessage('ì´ì „ì— ì‚¬ìš©í•œ ìŒì„± ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.');
        return;
      }
      if (data) {
        const files = data
          .filter((item: StorageObject) => item.name.endsWith('.wav') || item.name.endsWith('.webm'))
          .map((item: StorageObject) => ({
            name: item.name,
            file: `/reference/${userId}/${item.name}`,
          }));
        setUsedAudioFiles(files);
      }
    } catch {
      setErrorMessage('ì´ì „ì— ì‚¬ìš©í•œ ìŒì„± ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    }
  }, [userId, supabase]);

  // ì´ì „ì— ì‚¬ìš©í•œ ìŒì„± ì„ íƒ í•¸ë“¤ëŸ¬ (signed URL ì ìš©)
  const handleUsedAudioSelect = useCallback(async (audioFile: string) => {
    // signed URL ë°œê¸‰
    const filePath = audioFile.startsWith('/reference/')
      ? audioFile.replace('/reference/', 'reference/')
      : audioFile;
    const { data, error } = await supabase.storage
      .from('prototype')
      .createSignedUrl(filePath, 60 * 60 * 24 * 30); // 30ì¼

    if (error || !data?.signedUrl) {
      setErrorMessage('ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.');
      return;
    }

    // ì´ì „ì— ì‚¬ìš©í•œ ìŒì„±ì„ì„ í‘œì‹œí•˜ê¸° ìœ„í•´ selectedUsedAudio ìƒíƒœ ì‚¬ìš©
    setSelectedPresetAudio(null); // ë¯¸ë¦¬ ì„ íƒëœ ì˜¤ë””ì˜¤ ì´ˆê¸°í™”
    setUsedAudioFile(filePath); // ìƒˆë¡œìš´ ìƒíƒœë¡œ ì´ì „ ì‚¬ìš© ìŒì„± ì €ì¥
    setAudioUrl(data.signedUrl);
    setShowPreview(true);
    setCurrentStep('preview');
    const audio = new Audio(data.signedUrl);
    setAudioElement(audio);
    setIsPlaying(false);
    setCurrentTime(0);
    setDuration(0);
    setRecordedAudioBlob(null);
    setAudioChunks([]);
    setRecordingTime(0);
    setShowUsedAudioList(false);
  }, [supabase]);

  const props = useSupabaseUpload({
    bucketName: 'prototype',
    path: userId ? `reference/${userId}` : undefined,
    allowedMimeTypes: ['audio/*'],
    maxFiles: 1,
    maxFileSize: 1000 * 1000 * 10, // 10MB
    upsert: true,
    onSuccess: onUploadSuccess,
  })

  // ë…¹ìŒ ì‹œì‘ ì‹œ íŒŒì¼ ì—…ë¡œë“œ ì´ˆê¸°í™”
  const startRecordingWithFileReset = useCallback(async () => {
    // ê¸°ì¡´ íŒŒì¼ ì—…ë¡œë“œ ì´ˆê¸°í™”
    props.setFiles([])
    // ë¯¸ë¦¬ ì„ íƒëœ ì˜¤ë””ì˜¤ ì´ˆê¸°í™”
    setSelectedPresetAudio(null)
    // ë…¹ìŒ ì‹œì‘
    await startRecording()
  }, [props, startRecording])

  // ë…¹ìŒ ì¬ì‹œì‘ ì‹œ íŒŒì¼ ì—…ë¡œë“œë„ ì´ˆê¸°í™”
  const restartRecordingWithFileReset = useCallback(() => {
    restartRecording()
    props.setFiles([])
    setSelectedPresetAudio(null)
  }, [restartRecording, props])

  // ë¯¸ë¦¬ ì„ íƒëœ ì˜¤ë””ì˜¤ ì„ íƒ ì‹œ íŒŒì¼ ì—…ë¡œë“œ ì´ˆê¸°í™”
  const handlePresetAudioSelectWithReset = useCallback((audioFile: string) => {
    console.log('handlePresetAudioSelectWithReset í˜¸ì¶œë¨:', audioFile)
    // ë¨¼ì € íŒŒì¼ ì—…ë¡œë“œ ì´ˆê¸°í™”
    props.setFiles([])
    // ì´ì „ ì‚¬ìš© ìŒì„± ì´ˆê¸°í™”
    setUsedAudioFile(null)
    // ê·¸ ë‹¤ìŒ ë¯¸ë¦¬ ì„ íƒëœ ì˜¤ë””ì˜¤ ì„¤ì •
    handlePresetAudioSelect(audioFile)
  }, [handlePresetAudioSelect, props])

  // íŒŒì¼ì´ ì„ íƒë˜ë©´ ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
  useEffect(() => {
    if (props.files.length > 0) {
      // ê¸°ì¡´ ì˜¤ë””ì˜¤ ì •ë¦¬
      if (audioUrlRef.current) {
        URL.revokeObjectURL(audioUrlRef.current)
      }
      setAudioUrl(null)
      setAudioElement(null)
      setIsPlaying(false)
      
      // ë…¹ìŒëœ ì˜¤ë””ì˜¤ ì´ˆê¸°í™”
      setRecordedAudioBlob(null)
      setAudioChunks([])
      setRecordingTime(0)
      
      // ë¯¸ë¦¬ ì„ íƒëœ ì˜¤ë””ì˜¤ ë° ì´ì „ ì‚¬ìš© ìŒì„± ì´ˆê¸°í™” (íŒŒì¼ì´ ì‹¤ì œë¡œ ì—…ë¡œë“œëœ ê²½ìš°ì—ë§Œ)
      if (props.files.length > 0) {
        setSelectedPresetAudio(null)
        setUsedAudioFile(null)
      }
      
      // ìƒˆë¡œìš´ íŒŒì¼ ì„¤ì •
      handleFileSelect(props.files)
    } else {
      // íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¯¸ë¦¬ë³´ê¸° ìˆ¨ê¸°ê¸° (ë¯¸ë¦¬ ì„ íƒëœ ì˜¤ë””ì˜¤ë‚˜ ì´ì „ ì‚¬ìš© ìŒì„±ì´ ì—†ì„ ë•Œë§Œ)
      if (!selectedPresetAudio && !usedAudioFile) {
        clearAudioPreview()
      }
    }
  }, [props.files, handleFileSelect, clearAudioPreview, selectedPresetAudio, usedAudioFile])

  // ìƒíƒœ ë³€í™” ë””ë²„ê¹…ì„ ìœ„í•œ useEffect
  useEffect(() => {
    console.log('ìƒíƒœ ë³€í™”:', {
      currentStep,
      showPreview,
      selectedPresetAudio,
      audioUrl
    })
  }, [currentStep, showPreview, selectedPresetAudio, audioUrl])

  // ë¯¸ë¦¬ ì„ íƒëœ ì˜¤ë””ì˜¤ ì²˜ë¦¬ í•¨ìˆ˜

  // ì‹œê°„ í¬ë§· í•¨ìˆ˜
  const formatTime = (seconds: number) => {
    if (isNaN(seconds) || seconds === Infinity) return '0:00';
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  // ì§„í–‰ë¥  ë°” í´ë¦­ í•¸ë“¤ëŸ¬
  const handleProgressClick = (e: React.MouseEvent<HTMLDivElement>) => {
    if (!audioElement || duration === 0) return;
    
    const rect = e.currentTarget.getBoundingClientRect();
    const clickX = e.clientX - rect.left;
    const percentage = (clickX / rect.width) * 100;
    const newTime = (percentage / 100) * duration;
    
    audioElement.currentTime = newTime;
    setCurrentTime(newTime);
  };

  return (
    <div className="w-full max-w-md mx-auto px-4 sm:px-0">
      {userId ? (
        <div className="space-y-4 sm:space-y-6">
          {/* ë‹¨ê³„ í‘œì‹œ */}
          <div className="flex items-center justify-center space-x-4 sm:space-x-8 mb-6 sm:mb-8">
                          <div className={`flex items-center space-x-1 sm:space-x-2 ${currentStep === 'upload' ? 'text-blue-600 dark:text-blue-400' : 'text-gray-500 dark:text-gray-400'}`}>
                <div className={`w-5 h-5 sm:w-6 sm:h-6 rounded-full flex items-center justify-center text-xs font-medium ${
                  currentStep === 'upload' ? 'bg-blue-500 text-white' : 'bg-gray-300 dark:bg-gray-700 text-gray-600 dark:text-gray-400'
                }`}>
                  1
                </div>
                <span className="text-xs sm:text-sm font-medium hidden sm:inline">ì—…ë¡œë“œ</span>
              </div>
              <div className={`flex items-center space-x-1 sm:space-x-2 ${currentStep === 'preview' ? 'text-blue-600 dark:text-blue-400' : 'text-gray-500 dark:text-gray-400'}`}>
                <div className={`w-5 h-5 sm:w-6 sm:h-6 rounded-full flex items-center justify-center text-xs font-medium ${
                  currentStep === 'preview' ? 'bg-blue-500 text-white' : 'bg-gray-300 dark:bg-gray-700 text-gray-600 dark:text-gray-400'
                }`}>
                  2
                </div>
                <span className="text-xs sm:text-sm font-medium hidden sm:inline">ë¯¸ë¦¬ë“£ê¸°</span>
              </div>
              <div className={`flex items-center space-x-1 sm:space-x-2 ${currentStep === 'text' ? 'text-blue-600 dark:text-blue-400' : 'text-gray-500 dark:text-gray-400'}`}>
                <div className={`w-5 h-5 sm:w-6 sm:h-6 rounded-full flex items-center justify-center text-xs font-medium ${
                  currentStep === 'text' ? 'bg-blue-500 text-white' : 'bg-gray-300 dark:bg-gray-700 text-gray-600 dark:text-gray-400'
                }`}>
                  3
                </div>
                <span className="text-xs sm:text-sm font-medium hidden sm:inline">í…ìŠ¤íŠ¸</span>
              </div>
          </div>
          {errorMessage && (
            <div className="p-3 bg-red-50 dark:bg-red-900/50 border border-red-200 dark:border-red-700 text-red-700 dark:text-red-300 rounded-lg text-sm">
              {errorMessage}
            </div>
          )}
          
          {isProcessing && (
            <div className="p-3 bg-blue-50 dark:bg-blue-900/50 border border-blue-200 dark:border-blue-700 text-blue-700 dark:text-blue-300 rounded-lg text-sm">
              TTS ì²˜ë¦¬ë¥¼ ì‹œì‘í•˜ê³  ìˆìŠµë‹ˆë‹¤...
            </div>
          )}

          {/* Step 1: ì—…ë¡œë“œ/ë…¹ìŒ */}
          {currentStep === 'upload' && (
            <div className="space-y-4 sm:space-y-6">
              {/* ë…¹ìŒ ë²„íŠ¼ */}
              <div className="text-center">
                {!isRecording ? (
                  <div className="flex justify-center">
                    <button
                      onClick={startRecordingWithFileReset}
                      className="w-14 h-14 sm:w-16 sm:h-16 bg-gradient-to-r from-pink-500 to-purple-500 rounded-full flex items-center justify-center text-white shadow-lg hover:shadow-xl transition-all duration-200 touch-manipulation"
                    >
                      <Mic size={20} className="sm:w-6 sm:h-6" />
                    </button>
                  </div>
                ) : (
                  <div className="space-y-3">
                    <div className="flex items-center justify-center space-x-3">
                      <div className="w-3 h-3 bg-red-500 rounded-full animate-pulse"></div>
                      <span className="text-sm font-medium text-red-400">
                        {Math.floor(recordingTime / 60)}:{(recordingTime % 60).toString().padStart(2, '0')}
                      </span>
                    </div>
                    <div className="flex justify-center">
                      <button
                        onClick={stopRecording}
                        className="w-14 h-14 sm:w-16 sm:h-16 bg-red-500 rounded-full flex items-center justify-center text-white shadow-lg hover:shadow-xl transition-all duration-200 touch-manipulation"
                      >
                        <Square size={20} className="sm:w-6 sm:h-6" />
                      </button>
                    </div>
                  </div>
                )}
                <p className="text-xs text-gray-500 dark:text-gray-400 mt-2">
                  {isRecording ? 'ë…¹ìŒ ì¤‘ì§€' : 'ë…¹ìŒí•˜ê¸°'}
                </p>
              </div>

              {/* ë˜ëŠ” êµ¬ë¶„ì„  */}
              <div className="flex items-center">
                <div className="flex-1 h-px bg-gray-300 dark:bg-gray-700"></div>
                <span className="px-4 text-xs text-gray-500 dark:text-gray-400">ë˜ëŠ”</span>
                <div className="flex-1 h-px bg-gray-300 dark:bg-gray-700"></div>
              </div>

              {/* ë¯¸ë¦¬ ì„ íƒëœ ì˜¤ë””ì˜¤ ëª©ë¡ */}
              <div className="text-center">
                <button
                  onClick={() => setShowPresetAudioList(!showPresetAudioList)}
                  className="w-full py-3 px-4 bg-gradient-to-r from-blue-500 to-indigo-500 text-white rounded-lg font-medium hover:from-blue-600 hover:to-indigo-600 transition-all duration-200 flex items-center justify-center space-x-2 touch-manipulation"
                >
                  <Music size={18} className="sm:w-5 sm:h-5" />
                  <span className="text-sm sm:text-base">ë¯¸ë¦¬ ì¤€ë¹„ëœ ìŒì„± ì„ íƒ (beta)</span>
                </button>
                
                {showPresetAudioList && (
                  <div className="mt-4 space-y-2 max-h-60 overflow-y-auto">
                    {PRESET_AUDIO_FILES.map((audio, index) => (
                      <button
                        key={index}
                        onClick={() => {
                          console.log('ë¯¸ë¦¬ ì„ íƒëœ ì˜¤ë””ì˜¤ ë²„íŠ¼ í´ë¦­ë¨:', audio.file)
                          handlePresetAudioSelectWithReset(audio.file)
                        }}
                        className="w-full p-3 text-left bg-white dark:bg-gray-800 border border-gray-200 dark:border-gray-700 rounded-lg hover:bg-gray-50 dark:hover:bg-gray-700 transition-colors touch-manipulation"
                      >
                        <div className="flex items-center justify-between">
                          <div className="flex items-center space-x-2 sm:space-x-3">
                            <div className="w-6 h-6 sm:w-8 sm:h-8 bg-gradient-to-r from-blue-400 to-purple-400 rounded-full flex items-center justify-center">
                              <Music size={14} className="sm:w-4 sm:h-4 text-white" />
                            </div>
                            <div className="text-left flex-1 min-w-0">
                              <p className="text-sm font-medium text-gray-900 dark:text-white truncate">
                                {audio.name}
                              </p>
                              <p className="text-xs text-gray-500 dark:text-gray-400">
                                {audio.duration}
                              </p>
                            </div>
                          </div>
                          <div className="text-xs text-gray-400 dark:text-gray-500 ml-2">
                            ì„ íƒ
                          </div>
                        </div>
                      </button>
                    ))}
                  </div>
                )}
              </div>

              {/* ì´ì „ì— ì‚¬ìš©í•œ ìŒì„± ì„ íƒ ë²„íŠ¼ */}
              <button
                onClick={async () => {
                  if (!showUsedAudioList) await fetchUsedAudioFiles();
                  setShowUsedAudioList(!showUsedAudioList);
                }}
                className="w-full mt-3 py-3 px-4 bg-gradient-to-r from-green-500 to-teal-500 text-white rounded-lg font-medium hover:from-green-600 hover:to-teal-600 transition-all duration-200 flex items-center justify-center space-x-2 touch-manipulation"
              >
                <Music size={18} className="sm:w-5 sm:h-5" />
                <span className="text-sm sm:text-base">ì´ì „ì— ì‚¬ìš©í•œ ìŒì„± ì„ íƒ</span>
              </button>
              {showUsedAudioList && (
                <div className="mt-4 space-y-2 max-h-60 overflow-y-auto">
                  {usedAudioFiles.length === 0 ? (
                    <div className="text-xs text-gray-500 dark:text-gray-400">ì´ì „ì— ì—…ë¡œë“œí•œ ìŒì„±ì´ ì—†ìŠµë‹ˆë‹¤.</div>
                  ) : (
                    usedAudioFiles.map((audio, index) => (
                      <button
                        key={index}
                        onClick={() => handleUsedAudioSelect(audio.file)}
                        className="w-full p-3 text-left bg-white dark:bg-gray-800 border border-gray-200 dark:border-gray-700 rounded-lg hover:bg-gray-50 dark:hover:bg-gray-700 transition-colors touch-manipulation"
                      >
                        <div className="flex items-center justify-between">
                          <div className="flex items-center space-x-2 sm:space-x-3">
                            <div className="w-6 h-6 sm:w-8 sm:h-8 bg-gradient-to-r from-green-400 to-teal-400 rounded-full flex items-center justify-center">
                              <Music size={14} className="sm:w-4 sm:h-4 text-white" />
                            </div>
                            <div className="text-left flex-1 min-w-0">
                              <p className="text-sm font-medium text-gray-900 dark:text-white truncate">
                                {audio.name}
                              </p>
                            </div>
                          </div>
                          <div className="text-xs text-gray-400 dark:text-gray-500 ml-2">
                            ì„ íƒ
                          </div>
                        </div>
                      </button>
                    ))
                  )}
                </div>
              )}

              {/* ë˜ëŠ” êµ¬ë¶„ì„  */}
              <div className="flex items-center">
                <div className="flex-1 h-px bg-gray-300 dark:bg-gray-700"></div>
                <span className="px-4 text-xs text-gray-500 dark:text-gray-400">ë˜ëŠ”</span>
                <div className="flex-1 h-px bg-gray-300 dark:bg-gray-700"></div>
              </div>

              {/* íŒŒì¼ ì—…ë¡œë“œ */}
              <div className="text-center">
                <Dropzone {...props} className="border-2 border-dashed border-gray-300 dark:border-gray-600 rounded-lg p-4 sm:p-8 hover:border-gray-400 dark:hover:border-gray-500 transition-colors bg-gray-50 dark:bg-gray-900/50">
                  <DropzoneEmptyState />
                  <DropzoneContent />
                </Dropzone>
              </div>
            </div>
          )}

          {/* Step 2: ë¯¸ë¦¬ë“£ê¸° */}
          {(() => {
            const shouldShowPreview = currentStep === 'preview' && (showPreview || selectedPresetAudio || usedAudioFile)
            console.log('ë¯¸ë¦¬ë“£ê¸° ì¡°ê±´ í™•ì¸:', {
              currentStep,
              showPreview,
              selectedPresetAudio,
              usedAudioFile,
              shouldShowPreview
            })
            return shouldShowPreview
          })() && (
            <div className="space-y-4 sm:space-y-6">
              {/* ë¯¸ë¦¬ë“£ê¸° í—¤ë” */}
              <div className="flex items-center justify-between">
                <span className="text-sm font-medium text-gray-700 dark:text-gray-200">
                  {recordedAudioBlob ? 'ë…¹ìŒ ì™„ë£Œ Â· ë¯¸ë¦¬ë“£ê¸°' : 
                   selectedPresetAudio ? 'ë¯¸ë¦¬ ì¤€ë¹„ëœ ìŒì„± Â· ë¯¸ë¦¬ë“£ê¸°' : 
                   usedAudioFile ? 'ì´ì „ ì‚¬ìš© ìŒì„± Â· ë¯¸ë¦¬ë“£ê¸°' :
                   'ì—…ë¡œë“œ ì™„ë£Œ Â· ë¯¸ë¦¬ë“£ê¸°'}
                </span>
                <button
                  onClick={() => {
                    restartRecordingWithFileReset()
                    setSelectedPresetAudio(null)
                    setUsedAudioFile(null)
                  }}
                  className="text-xs text-gray-500 dark:text-gray-400 hover:text-gray-700 dark:hover:text-gray-300 transition-colors"
                >
                  <RotateCcw size={14} />
                </button>
              </div>

              {/* ë¯¸ë‹ˆë©€ ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ */}
              <div className="bg-gray-100 dark:bg-gray-900/50 rounded-lg p-3 sm:p-4 border border-gray-300 dark:border-gray-700">
                {/* ìˆ¨ê²¨ì§„ ì˜¤ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ */}
                {audioUrl && (
                  <audio
                    ref={(el) => {
                      if (el) setAudioElement(el)
                    }}
                    src={audioUrl}
                    preload="metadata"
                    style={{ display: 'none' }}
                  />
                )}
                
                <div className="flex items-center space-x-2 sm:space-x-3">
                  <button
                    onClick={togglePlayPause}
                    className="w-8 h-8 sm:w-10 sm:h-10 bg-gray-200 dark:bg-gray-800 rounded-full flex items-center justify-center shadow-sm hover:shadow-md transition-shadow border border-gray-300 dark:border-gray-600 touch-manipulation"
                  >
                    {isPlaying ? <Pause size={14} className="sm:w-4 sm:h-4 text-gray-700 dark:text-white" /> : <Play size={14} className="sm:w-4 sm:h-4 text-gray-700 dark:text-white" />}
                  </button>
                  <div className="flex-1 space-y-1">
                    <div 
                      className="h-1 bg-gray-300 dark:bg-gray-700 rounded-full overflow-hidden cursor-pointer"
                      onClick={handleProgressClick}
                    >
                      <div 
                        className="h-full bg-gradient-to-r from-pink-500 to-purple-500 rounded-full transition-all duration-300"
                        style={{ width: duration > 0 && !isNaN(duration) ? `${(currentTime / duration) * 100}%` : '0%' }}
                      ></div>
                    </div>
                    <div className="flex justify-between text-xs text-gray-500 dark:text-gray-400">
                      <span>
                        {formatTime(currentTime)}
                      </span>
                      <span>
                        {isNaN(duration) ? '0:00' : formatTime(duration)}
                      </span>
                    </div>
                  </div>
                </div>
              </div>

              {/* ë‹¤ìŒ ë‹¨ê³„ ë²„íŠ¼ */}
              <button
                onClick={() => setCurrentStep('text')}
                className="w-full bg-gradient-to-r from-blue-500 to-purple-500 text-white py-3 rounded-full font-medium hover:from-blue-600 hover:to-purple-600 transition-all duration-200 touch-manipulation"
              >
                ë‹¤ìŒ ë‹¨ê³„
              </button>
            </div>
          )}

          {/* Step 3: í…ìŠ¤íŠ¸ ì…ë ¥ */}
          {currentStep === 'text' && (
            <div className="space-y-4 sm:space-y-6">
              <div className="space-y-2">
                <label className="text-sm font-medium text-gray-700 dark:text-gray-200">ë³€í™˜í•  í…ìŠ¤íŠ¸</label>
                
                {/* í…ìŠ¤íŠ¸ ì˜ˆì‹œ ì„ íƒ ë²„íŠ¼ */}
                <button
                  type="button"
                  onClick={() => setShowTextExamples(!showTextExamples)}
                  className="w-full py-2 px-3 text-sm border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-800 text-gray-700 dark:text-gray-300 hover:bg-gray-100 dark:hover:bg-gray-700 transition-colors flex items-center justify-between touch-manipulation"
                >
                  <span>í…ìŠ¤íŠ¸ ì˜ˆì‹œ ì„ íƒí•˜ê¸°</span>
                  <span className="text-xs text-gray-500 dark:text-gray-400">
                    {showTextExamples ? 'ì ‘ê¸°' : 'í¼ì¹˜ê¸°'}
                  </span>
                </button>
                
                {/* í…ìŠ¤íŠ¸ ì˜ˆì‹œ ëª©ë¡ */}
                {showTextExamples && (
                  <div className="space-y-2 max-h-60 overflow-y-auto border border-gray-200 dark:border-gray-700 rounded-lg p-3 bg-white dark:bg-gray-900">
                    {TEXT_EXAMPLES.map((example) => (
                      <button
                        key={example.id}
                        onClick={() => handleTextExampleSelect(example.text)}
                        className="w-full p-3 text-left border border-gray-200 dark:border-gray-700 rounded-lg hover:bg-gray-50 dark:hover:bg-gray-800 transition-colors touch-manipulation"
                      >
                        <div className="space-y-1">
                          <p className="text-sm font-medium text-gray-900 dark:text-white">
                            {example.title}
                          </p>
                          <p className="text-xs text-gray-600 dark:text-gray-400 line-clamp-2">
                            {example.text}
                          </p>
                        </div>
                      </button>
                    ))}
                  </div>
                )}
                
                <textarea
                  id="tts-text-input"
                  name="tts-text-input"
                  value={gen_text}
                  onChange={(e) => {
                    const value = e.target.value;
                    if (value.length <= 150) {
                      setGenText(value);
                    }
                  }}
                  placeholder="ì›í•˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”... (ìµœëŒ€ 150ì)"
                  maxLength={150}
                  className="w-full h-24 px-3 sm:px-4 py-3 border border-gray-300 dark:border-gray-600 rounded-lg resize-none focus:outline-none focus:ring-2 focus:ring-blue-500 focus:border-transparent bg-white dark:bg-gray-900 text-gray-900 dark:text-white placeholder-gray-500 dark:placeholder-gray-400 text-sm sm:text-base"
                />
                <div className="flex justify-end">
                  <span className={`text-xs ${gen_text.length >= 150 ? 'text-red-500' : 'text-gray-500 dark:text-gray-400'}`}>
                    {gen_text.length}/150
                  </span>
                </div>
              </div>

              {/* í ìƒíƒœ í‘œì‹œ */}
              {currentRequestId && (
                <div className="mt-4 p-4 bg-blue-50 dark:bg-blue-900/20 border border-blue-200 dark:border-blue-800 rounded-lg">
                  <QueueStatusDisplay requestId={currentRequestId} />
                </div>
              )}
              {/* ë””ë²„ê¹…ìš© ë¡œê·¸ */}
              {(() => { console.log('currentRequestId:', currentRequestId); return null; })()}

              {/* TTS ìƒì„± ì‹œì‘ ë²„íŠ¼ */}
              <button
                onClick={() => {
                  // íŒŒì¼ ì—…ë¡œë“œì¸ ê²½ìš° props.onUpload í˜¸ì¶œ, ë‹¤ë¥¸ ê²½ìš° startTTS í˜¸ì¶œ
                  if (!recordedAudioBlob && !selectedPresetAudio && !usedAudioFile && props.files.length > 0) {
                    props.onUpload()
                  } else {
                    startTTS()
                  }
                }}
                disabled={
                  (props.files.length > 0 && props.files.some((file) => file.errors.length !== 0)) || 
                  !gen_text.trim() ||
                  isProcessing
                }
                className="w-full bg-gradient-to-r from-pink-500 to-purple-500 text-white py-4 rounded-full font-medium hover:from-pink-600 hover:to-purple-600 transition-all duration-200 disabled:opacity-50 disabled:cursor-not-allowed touch-manipulation"
              >
                {isProcessing ? 'ì²˜ë¦¬ ì¤‘...' : 'TTS ìƒì„± ì‹œì‘'}
              </button>
            </div>
          )}
        </div>
      ) : (
        <div className="text-center text-gray-500 dark:text-gray-400">Loading user...</div>
      )}
    </div>
  )
}

export default FileUploadDemo
