'use client'

import { Dropzone, DropzoneContent, DropzoneEmptyState } from '@/components/dropzone'
import { createClient } from '@/lib/supabase/client'
import { useSupabaseUpload } from '@/hooks/use-supabase-upload'
import { useEffect, useState, useCallback, useRef } from 'react'
import { useRouter } from 'next/navigation'
import { Button } from '@/components/ui/button'
import { Play, Pause, Volume2, Mic, Square, RotateCcw } from 'lucide-react'

const FileUploadDemo = () => {
  const [userId, setUserId] = useState<string | null>(null)
  const [gen_text, setGenText] = useState('')
  const [isProcessing, setIsProcessing] = useState(false)
  const [errorMessage, setErrorMessage] = useState('')
  const [showPreview, setShowPreview] = useState(false)
  const [audioUrl, setAudioUrl] = useState<string | null>(null)
  const [isPlaying, setIsPlaying] = useState(false)
  const [audioElement, setAudioElement] = useState<HTMLAudioElement | null>(null)
  const audioUrlRef = useRef<string | null>(null)
  
  // ë…¹ìŒ ê´€ë ¨ ìƒíƒœ
  const [isRecording, setIsRecording] = useState(false)
  const [recordingTime, setRecordingTime] = useState(0)
  const [mediaRecorder, setMediaRecorder] = useState<MediaRecorder | null>(null)
  const [audioChunks, setAudioChunks] = useState<Blob[]>([])
  const [recordedAudioBlob, setRecordedAudioBlob] = useState<Blob | null>(null)
  const [recordingTimer, setRecordingTimer] = useState<NodeJS.Timeout | null>(null)
  
  const supabase = createClient()
  const router = useRouter()

  // audioUrlì´ ë³€ê²½ë  ë•Œë§ˆë‹¤ ref ì—…ë°ì´íŠ¸
  useEffect(() => {
    audioUrlRef.current = audioUrl
  }, [audioUrl])

  useEffect(() => {
    const fetchUser = async () => {
      const {
        data: { user },
      } = await supabase.auth.getUser()
      if (user) {
        setUserId(user.id)
      }
    }
    fetchUser()
  }, [supabase])

  // ì˜¤ë””ì˜¤ ì¬ìƒ/ì¼ì‹œì •ì§€ í† ê¸€
  const togglePlayPause = useCallback(() => {
    if (audioElement) {
      if (isPlaying) {
        audioElement.pause()
      } else {
        audioElement.play()
      }
      setIsPlaying(!isPlaying)
    }
  }, [audioElement, isPlaying])

  // ì˜¤ë””ì˜¤ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì„¤ì •
  useEffect(() => {
    if (audioElement) {
      const handleEnded = () => setIsPlaying(false)
      const handlePlay = () => setIsPlaying(true)
      const handlePause = () => setIsPlaying(false)

      audioElement.addEventListener('ended', handleEnded)
      audioElement.addEventListener('play', handlePlay)
      audioElement.addEventListener('pause', handlePause)

      return () => {
        audioElement.removeEventListener('ended', handleEnded)
        audioElement.removeEventListener('play', handlePlay)
        audioElement.removeEventListener('pause', handlePause)
      }
    }
  }, [audioElement])

  // íŒŒì¼ì´ ì„ íƒë˜ë©´ ë¯¸ë¦¬ë³´ê¸° URL ìƒì„±
  const handleFileSelect = useCallback((files: File[]) => {
    if (files.length > 0) {
      const file = files[0]
      const url = URL.createObjectURL(file)
      setAudioUrl(url)
      setShowPreview(true)
      
      // ìƒˆë¡œìš´ ì˜¤ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ ìƒì„±
      const audio = new Audio(url)
      setAudioElement(audio)
      setIsPlaying(false)
    }
  }, [])

  // íŒŒì¼ ì •ë¦¬ í•¨ìˆ˜
  const clearAudioPreview = useCallback(() => {
    setShowPreview(false)
    if (audioUrlRef.current) {
      URL.revokeObjectURL(audioUrlRef.current)
      setAudioUrl(null)
    }
    setAudioElement(null)
    setIsPlaying(false)
  }, [])

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ URL ì •ë¦¬
  useEffect(() => {
    return () => {
      if (audioUrlRef.current) {
        URL.revokeObjectURL(audioUrlRef.current)
      }
      // ë…¹ìŒ íƒ€ì´ë¨¸ ì •ë¦¬
      if (recordingTimer) {
        clearInterval(recordingTimer)
      }
    }
  }, [recordingTimer])

  // ë…¹ìŒ ì‹œì‘ í•¨ìˆ˜
  const startRecording = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      const recorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      })
      
      const chunks: Blob[] = []
      
      recorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunks.push(event.data)
        }
      }
      
      recorder.onstop = () => {
        const blob = new Blob(chunks, { type: 'audio/webm' })
        setRecordedAudioBlob(blob)
        setAudioChunks(chunks)
        
        // ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
        stream.getTracks().forEach(track => track.stop())
      }
      
      recorder.start()
      setMediaRecorder(recorder)
      setIsRecording(true)
      setRecordingTime(0)
      
      // ë…¹ìŒ ì‹œê°„ íƒ€ì´ë¨¸ ì‹œì‘
      const timer = setInterval(() => {
        setRecordingTime(prev => prev + 1)
      }, 1000)
      setRecordingTimer(timer)
      
    } catch (error) {
      console.error('ë…¹ìŒì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤:', error)
      setErrorMessage('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.')
    }
  }, [])

  // ë…¹ìŒ ì¤‘ì§€ í•¨ìˆ˜
  const stopRecording = useCallback(() => {
    if (mediaRecorder && isRecording) {
      mediaRecorder.stop()
      setIsRecording(false)
      
      // íƒ€ì´ë¨¸ ì •ë¦¬
      if (recordingTimer) {
        clearInterval(recordingTimer)
        setRecordingTimer(null)
      }
    }
  }, [mediaRecorder, isRecording, recordingTimer])

  // ë…¹ìŒ ì¬ì‹œì‘ í•¨ìˆ˜
  const restartRecording = useCallback(() => {
    setRecordedAudioBlob(null)
    setAudioChunks([])
    setRecordingTime(0)
    setShowPreview(false)
    if (audioUrlRef.current) {
      URL.revokeObjectURL(audioUrlRef.current)
      setAudioUrl(null)
    }
    setAudioElement(null)
    setIsPlaying(false)
  }, [])

  // ë…¹ìŒëœ ì˜¤ë””ì˜¤ë¥¼ íŒŒì¼ë¡œ ë³€í™˜í•˜ê³  ë¯¸ë¦¬ë³´ê¸° ì„¤ì •
  const handleRecordedAudio = useCallback(() => {
    if (recordedAudioBlob) {
      const url = URL.createObjectURL(recordedAudioBlob)
      setAudioUrl(url)
      setShowPreview(true)
      
      // ìƒˆë¡œìš´ ì˜¤ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ ìƒì„±
      const audio = new Audio(url)
      setAudioElement(audio)
      setIsPlaying(false)
    }
  }, [recordedAudioBlob])

  // ë…¹ìŒëœ ì˜¤ë””ì˜¤ê°€ ë³€ê²½ë  ë•Œë§ˆë‹¤ ë¯¸ë¦¬ë³´ê¸° ì„¤ì •
  useEffect(() => {
    if (recordedAudioBlob) {
      handleRecordedAudio()
    }
  }, [recordedAudioBlob, handleRecordedAudio])

  // ë…¹ìŒëœ ì˜¤ë””ì˜¤ë¥¼ Supabaseì— ì—…ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
  const uploadRecordedAudio = useCallback(async (): Promise<string | null> => {
    if (!recordedAudioBlob || !userId) return null
    
    try {
      // Blobì„ File ê°ì²´ë¡œ ë³€í™˜
      const file = new File([recordedAudioBlob], `recorded_audio_${Date.now()}.webm`, {
        type: 'audio/webm'
      })
      
      // Supabase Storageì— ì—…ë¡œë“œ
      const fileName = `reference/${userId}/recorded_${Date.now()}.webm`
      const { data, error } = await supabase.storage
        .from('prototype')
        .upload(fileName, file, {
          cacheControl: '3600',
          upsert: false
        })
      
      if (error) {
        console.error('ë…¹ìŒ ì˜¤ë””ì˜¤ ì—…ë¡œë“œ ì‹¤íŒ¨:', error)
        setErrorMessage('ë…¹ìŒ ì˜¤ë””ì˜¤ ì—…ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.')
        return null
      }
      
      return fileName
    } catch (error) {
      console.error('ë…¹ìŒ ì˜¤ë””ì˜¤ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜:', error)
      setErrorMessage('ë…¹ìŒ ì˜¤ë””ì˜¤ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')
      return null
    }
  }, [recordedAudioBlob, userId, supabase])

  // ì—…ë¡œë“œ ì„±ê³µ ì‹œ tts_requestsì— í–‰ ì‚½ì… + TTS Runner í˜¸ì¶œ + í˜ì´ì§€ ì´ë™
  const onUploadSuccess = useCallback(
    async (uploadedFileUrls: string[]) => {
      if (!userId || uploadedFileUrls.length === 0) return
      
      setIsProcessing(true)
      setErrorMessage('')

      const filePath = uploadedFileUrls[0]

      // 1ë‹¬(2592000ì´ˆ)ì§œë¦¬ signed URL ìƒì„±
      const { data, error: urlError } = await supabase
        .storage
        .from('prototype')
        .createSignedUrl(filePath, 60 * 60 * 24 * 30) // 30ì¼

      if (urlError || !data?.signedUrl) {
        console.error('Error creating signed URL:', urlError?.message)
        setErrorMessage('Signed URL ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.')
        setIsProcessing(false)
        return
      }

      const signedUrl = data.signedUrl

      // 1ë‹¨ê³„: tts_requests í…Œì´ë¸”ì— INSERT
      const { data: insertData, error } = await supabase
        .from('tts_requests')
        .insert({
          user_id: userId,
          reference_audio_storage_path: filePath,
          reference_audio_url: signedUrl,
          gen_text: gen_text,
          status: 'pending',
        })
        .select('tts_id')
        .single()

      if (error) {
        console.error('Error inserting tts_request:', error.message)
        setErrorMessage('TTS ìš”ì²­ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.')
        setIsProcessing(false)
        return
      }

      if (!insertData?.tts_id) {
        console.error('No tts_id returned from insert')
        setErrorMessage('TTS ID ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.')
        setIsProcessing(false)
        return
      }

      // 2ë‹¨ê³„: TTS Runner Edge Function í˜¸ì¶œ
      try {
        console.log('Calling TTS Runner Edge Function...')
        console.log('Request payload:', {
          tts_id: insertData.tts_id,
          reference_audio_url: signedUrl,
          gen_text: gen_text,
          user_id: userId
        })
        
        const { data: functionData, error: functionError } = await supabase.functions.invoke('tts-runner', {
          body: {
            tts_id: insertData.tts_id,
            reference_audio_url: signedUrl,
            gen_text: gen_text,
            user_id: userId
          }
        })

        if (functionError) {
          console.error('Error calling TTS Runner:', functionError)
          console.error('Error details:', {
            message: functionError.message,
            name: functionError.name,
            status: functionError.status,
            statusText: functionError.statusText
          })
          
          // Update status to failed
          await supabase
            .from('tts_requests')
            .update({ 
              status: 'fail',
              error_message: `Edge Function Error: ${functionError.message}`
            })
            .eq('tts_id', insertData.tts_id)
        } else {
          console.log('TTS Runner called successfully:', functionData)
          // ì„±ê³µì ìœ¼ë¡œ í˜¸ì¶œë˜ë©´ ìƒíƒœë¥¼ 'in_progress'ë¡œ ì—…ë°ì´íŠ¸
          await supabase
            .from('tts_requests')
            .update({ status: 'in_progress' })
            .eq('tts_id', insertData.tts_id)
        }
      } catch (functionError) {
        console.error('Error calling TTS Runner function:', functionError)
        
        // Update status to failed
        await supabase
          .from('tts_requests')
          .update({ 
            status: 'fail',
            error_message: `Exception: ${functionError instanceof Error ? functionError.message : 'Unknown error'}`
          })
          .eq('tts_id', insertData.tts_id)
      }

      // 3ë‹¨ê³„: ê²°ê³¼ í™•ì¸ í˜ì´ì§€ë¡œ ì´ë™
      router.push(`/tts-result/${insertData.tts_id}`)
    },
    [userId, gen_text, supabase, router]
  )

  // ë…¹ìŒëœ ì˜¤ë””ì˜¤ë¡œ TTS ì‹œì‘í•˜ëŠ” í•¨ìˆ˜
  const startTTSWithRecordedAudio = useCallback(async () => {
    if (!userId || !recordedAudioBlob || !gen_text.trim()) return
    
    setIsProcessing(true)
    setErrorMessage('')
    
    try {
      // 1ë‹¨ê³„: ë…¹ìŒëœ ì˜¤ë””ì˜¤ ì—…ë¡œë“œ
      const filePath = await uploadRecordedAudio()
      if (!filePath) {
        setIsProcessing(false)
        return
      }
      
      // 2ë‹¨ê³„: signed URL ìƒì„±
      const { data, error: urlError } = await supabase
        .storage
        .from('prototype')
        .createSignedUrl(filePath, 60 * 60 * 24 * 30) // 30ì¼

      if (urlError || !data?.signedUrl) {
        console.error('Error creating signed URL:', urlError?.message)
        setErrorMessage('Signed URL ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.')
        setIsProcessing(false)
        return
      }

      const signedUrl = data.signedUrl

      // 3ë‹¨ê³„: tts_requests í…Œì´ë¸”ì— INSERT
      const { data: insertData, error } = await supabase
        .from('tts_requests')
        .insert({
          user_id: userId,
          reference_audio_storage_path: filePath,
          reference_audio_url: signedUrl,
          gen_text: gen_text,
          status: 'pending',
        })
        .select('tts_id')
        .single()

      if (error) {
        console.error('Error inserting tts_request:', error.message)
        setErrorMessage('TTS ìš”ì²­ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.')
        setIsProcessing(false)
        return
      }

      if (!insertData?.tts_id) {
        console.error('No tts_id returned from insert')
        setErrorMessage('TTS ID ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.')
        setIsProcessing(false)
        return
      }

      // 4ë‹¨ê³„: TTS Runner Edge Function í˜¸ì¶œ
      try {
        console.log('Calling TTS Runner Edge Function with recorded audio...')
        console.log('Request payload:', {
          tts_id: insertData.tts_id,
          reference_audio_url: signedUrl,
          gen_text: gen_text,
          user_id: userId
        })
        
        const { data: functionData, error: functionError } = await supabase.functions.invoke('tts-runner', {
          body: {
            tts_id: insertData.tts_id,
            reference_audio_url: signedUrl,
            gen_text: gen_text,
            user_id: userId
          }
        })

        if (functionError) {
          console.error('Error calling TTS Runner:', functionError)
          console.error('Error details:', {
            message: functionError.message,
            name: functionError.name,
            status: functionError.status,
            statusText: functionError.statusText
          })
          
          // Update status to failed
          await supabase
            .from('tts_requests')
            .update({ 
              status: 'fail',
              error_message: `Edge Function Error: ${functionError.message}`
            })
            .eq('tts_id', insertData.tts_id)
        } else {
          console.log('TTS Runner called successfully:', functionData)
          // ì„±ê³µì ìœ¼ë¡œ í˜¸ì¶œë˜ë©´ ìƒíƒœë¥¼ 'in_progress'ë¡œ ì—…ë°ì´íŠ¸
          await supabase
            .from('tts_requests')
            .update({ status: 'in_progress' })
            .eq('tts_id', insertData.tts_id)
        }
      } catch (functionError) {
        console.error('Error calling TTS Runner function:', functionError)
        
        // Update status to failed
        await supabase
          .from('tts_requests')
          .update({ 
            status: 'fail',
            error_message: `Exception: ${functionError instanceof Error ? functionError.message : 'Unknown error'}`
          })
          .eq('tts_id', insertData.tts_id)
      }

      // 5ë‹¨ê³„: ê²°ê³¼ í™•ì¸ í˜ì´ì§€ë¡œ ì´ë™
      router.push(`/tts-result/${insertData.tts_id}`)
      
    } catch (error) {
      console.error('ë…¹ìŒ ì˜¤ë””ì˜¤ TTS ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:', error)
      setErrorMessage('TTS ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')
      setIsProcessing(false)
    }
  }, [userId, recordedAudioBlob, gen_text, uploadRecordedAudio, supabase, router])

  const props = useSupabaseUpload({
    bucketName: 'prototype',
    path: userId ? `reference/${userId}` : undefined,
    allowedMimeTypes: ['audio/*'],
    maxFiles: 1,
    maxFileSize: 1000 * 1000 * 10, // 10MB
    upsert: true,
    onSuccess: onUploadSuccess,
  })

  // ë…¹ìŒ ì‹œì‘ ì‹œ íŒŒì¼ ì—…ë¡œë“œ ì´ˆê¸°í™”
  const startRecordingWithFileReset = useCallback(async () => {
    // ê¸°ì¡´ íŒŒì¼ ì—…ë¡œë“œ ì´ˆê¸°í™”
    props.setFiles([])
    // ë…¹ìŒ ì‹œì‘
    await startRecording()
  }, [props, startRecording])

  // ë…¹ìŒ ì¬ì‹œì‘ ì‹œ íŒŒì¼ ì—…ë¡œë“œë„ ì´ˆê¸°í™”
  const restartRecordingWithFileReset = useCallback(() => {
    restartRecording()
    props.setFiles([])
  }, [restartRecording, props])

  // íŒŒì¼ì´ ì„ íƒë˜ë©´ ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
  useEffect(() => {
    if (props.files.length > 0) {
      // ê¸°ì¡´ ì˜¤ë””ì˜¤ ì •ë¦¬
      if (audioUrlRef.current) {
        URL.revokeObjectURL(audioUrlRef.current)
      }
      setAudioUrl(null)
      setAudioElement(null)
      setIsPlaying(false)
      
      // ë…¹ìŒëœ ì˜¤ë””ì˜¤ ì´ˆê¸°í™”
      setRecordedAudioBlob(null)
      setAudioChunks([])
      setRecordingTime(0)
      
      // ìƒˆë¡œìš´ íŒŒì¼ ì„¤ì •
      handleFileSelect(props.files)
    } else {
      // íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¯¸ë¦¬ë³´ê¸° ìˆ¨ê¸°ê¸°
      clearAudioPreview()
    }
  }, [props.files, handleFileSelect, clearAudioPreview])

  return (
    <div className="w-[500px]">
      {userId ? (
        <>
          <input
            type="text"
            placeholder="ë³€í™˜í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
            value={gen_text}
            onChange={(e) => setGenText(e.target.value)}
            className="mb-4 w-full border border-gray-300 rounded px-2 py-1"
          />
          
          {errorMessage && (
            <div className="mb-4 p-3 bg-red-100 border border-red-400 text-red-700 rounded">
              {errorMessage}
            </div>
          )}
          
          {isProcessing && (
            <div className="mb-4 p-3 bg-blue-100 border border-blue-400 text-blue-700 rounded">
              TTS ì²˜ë¦¬ë¥¼ ì‹œì‘í•˜ê³  ìˆìŠµë‹ˆë‹¤...
            </div>
          )}

          {/* ë…¹ìŒ ì„¹ì…˜ */}
          <div className="mb-6 p-4 border border-gray-300 rounded-lg bg-gray-50">
            <h3 className="text-sm font-medium text-gray-700 mb-3 flex items-center gap-2">
              <Mic size={16} className="text-gray-500" />
              ì§ì ‘ ë…¹ìŒí•˜ê¸°
            </h3>
            
            {!isRecording && !recordedAudioBlob && (
              <div className="space-y-3">
                <p className="text-xs text-gray-600">
                  ë§ˆì´í¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ì ‘ ìŒì„±ì„ ë…¹ìŒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                </p>
                <Button
                  onClick={startRecordingWithFileReset}
                  className="w-full"
                  variant="outline"
                  size="sm"
                >
                  <Mic size={16} className="mr-2" />
                  ë…¹ìŒ ì‹œì‘
                </Button>
              </div>
            )}
            
            {isRecording && (
              <div className="space-y-3">
                <div className="flex items-center justify-between">
                  <div className="flex items-center gap-2">
                    <div className="w-3 h-3 bg-red-500 rounded-full animate-pulse"></div>
                    <span className="text-sm font-medium text-red-600">ë…¹ìŒ ì¤‘...</span>
                  </div>
                  <span className="text-sm text-gray-500">
                    {Math.floor(recordingTime / 60)}:{(recordingTime % 60).toString().padStart(2, '0')}
                  </span>
                </div>
                <Button
                  onClick={stopRecording}
                  className="w-full"
                  variant="destructive"
                  size="sm"
                >
                  <Square size={16} className="mr-2" />
                  ë…¹ìŒ ì¤‘ì§€
                </Button>
              </div>
            )}
            
            {recordedAudioBlob && !isRecording && (
              <div className="space-y-3">
                <div className="flex items-center justify-between">
                  <span className="text-sm font-medium text-green-600">ë…¹ìŒ ì™„ë£Œ</span>
                  <Button
                    onClick={restartRecordingWithFileReset}
                    variant="ghost"
                    size="sm"
                  >
                    <RotateCcw size={14} className="mr-1" />
                    ë‹¤ì‹œ ë…¹ìŒ
                  </Button>
                </div>
                <div className="text-xs text-gray-600 bg-white p-2 rounded border">
                  <p>âœ… ë…¹ìŒì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.</p>
                  <p>ğŸµ ì•„ë˜ ë¯¸ë¦¬ë³´ê¸°ì—ì„œ ë…¹ìŒëœ ìŒì„±ì„ í™•ì¸í•˜ì„¸ìš”.</p>
                </div>
              </div>
            )}
          </div>

          {/* ì˜¤ë””ì˜¤ ë¯¸ë¦¬ë³´ê¸° ì„¹ì…˜ */}
          {showPreview && audioUrl && (
            <div className="mb-4 p-4 border border-gray-300 rounded-lg bg-gray-50">
              <div className="flex items-center justify-between mb-3">
                <h3 className="text-sm font-medium text-gray-700 flex items-center gap-2">
                  <Volume2 size={16} className="text-gray-500" />
                  ì˜¤ë””ì˜¤ ë¯¸ë¦¬ë³´ê¸°
                </h3>
                <span className="text-xs text-gray-500 bg-white px-2 py-1 rounded">
                  {props.files[0]?.name}
                </span>
              </div>
              <div className="space-y-3">
                <div className="flex items-center gap-3">
                  <Button
                    onClick={togglePlayPause}
                    size="sm"
                    variant="outline"
                    className="flex items-center gap-2 min-w-[80px]"
                  >
                    {isPlaying ? <Pause size={16} /> : <Play size={16} />}
                    {isPlaying ? 'ì¼ì‹œì •ì§€' : 'ì¬ìƒ'}
                  </Button>
                  <div className="flex-1">
                    <audio
                      ref={(el) => {
                        if (el) setAudioElement(el)
                      }}
                      src={audioUrl}
                      className="w-full"
                      controls
                      preload="metadata"
                    />
                  </div>
                </div>
                <div className="text-xs text-gray-600 bg-white p-2 rounded border">
                  <p>âœ… ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.</p>
                  <p>ğŸµ ìœ„ì˜ ì»¨íŠ¸ë¡¤ì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ë¥¼ ë¯¸ë¦¬ ë“¤ì–´ë³´ì„¸ìš”.</p>
                  <p>ğŸ“ ë³€í™˜í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ê³  "TTS ìƒì„± ì‹œì‘" ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.</p>
                </div>
              </div>
            </div>
          )}
          
          <Dropzone {...props}>
            <DropzoneEmptyState />
            <DropzoneContent />
          </Dropzone>

          {/* TTS ìƒì„± ì‹œì‘ ë²„íŠ¼ */}
          {((showPreview && props.files.length > 0) || recordedAudioBlob) && !props.loading && (
            <div className="mt-4">
              <Button
                onClick={recordedAudioBlob ? startTTSWithRecordedAudio : props.onUpload}
                disabled={
                  (props.files.length > 0 && props.files.some((file) => file.errors.length !== 0)) || 
                  !gen_text.trim() ||
                  isProcessing
                }
                className="w-full"
                size="lg"
              >
                {isProcessing ? 'ì²˜ë¦¬ ì¤‘...' : 'TTS ìƒì„± ì‹œì‘'}
              </Button>
              {!gen_text.trim() && (
                <p className="text-xs text-red-500 mt-1">
                  ë³€í™˜í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.
                </p>
              )}
            </div>
          )}
        </>
      ) : (
        <div>Loading user...</div>
      )}
    </div>
  )
}

export { FileUploadDemo }
